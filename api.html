

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>API Reference &mdash; HidTen 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=2709fde1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Advanced" href="advanced.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            HidTen
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="algorithms.html">Algorithms for Inference and Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="emitters.html">Emitters</a></li>
<li class="toctree-l1"><a class="reference internal" href="transitioners.html">Transitioners</a></li>
<li class="toctree-l1"><a class="reference internal" href="priors.html">Priors</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced.html">Advanced</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#core-module">Core Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hmm-classes">HMM Classes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.hmm.HMM"><code class="docutils literal notranslate"><span class="pre">HMM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.add_emitter"><code class="docutils literal notranslate"><span class="pre">HMM.add_emitter()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.config"><code class="docutils literal notranslate"><span class="pre">HMM.config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.emission_scores"><code class="docutils literal notranslate"><span class="pre">HMM.emission_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.emitter"><code class="docutils literal notranslate"><span class="pre">HMM.emitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.joint_log_prob"><code class="docutils literal notranslate"><span class="pre">HMM.joint_log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.prior_scores"><code class="docutils literal notranslate"><span class="pre">HMM.prior_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.sample"><code class="docutils literal notranslate"><span class="pre">HMM.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.transitioner"><code class="docutils literal notranslate"><span class="pre">HMM.transitioner</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMM.use_padding"><code class="docutils literal notranslate"><span class="pre">HMM.use_padding()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.hmm.HMMConfig"><code class="docutils literal notranslate"><span class="pre">HMMConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMConfig.heads"><code class="docutils literal notranslate"><span class="pre">HMMConfig.heads</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMConfig.max_states"><code class="docutils literal notranslate"><span class="pre">HMMConfig.max_states</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMConfig.model_config"><code class="docutils literal notranslate"><span class="pre">HMMConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMConfig.states"><code class="docutils literal notranslate"><span class="pre">HMMConfig.states</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMConfig.validate_config"><code class="docutils literal notranslate"><span class="pre">HMMConfig.validate_config()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.hmm.HMMMode"><code class="docutils literal notranslate"><span class="pre">HMMMode</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.BACKWARD_LOG"><code class="docutils literal notranslate"><span class="pre">HMMMode.BACKWARD_LOG</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.EMISSION_SCORES"><code class="docutils literal notranslate"><span class="pre">HMMMode.EMISSION_SCORES</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.FORWARD_LOG"><code class="docutils literal notranslate"><span class="pre">HMMMode.FORWARD_LOG</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.FORWARD_SCALED"><code class="docutils literal notranslate"><span class="pre">HMMMode.FORWARD_SCALED</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.LIKELIHOOD_LOG"><code class="docutils literal notranslate"><span class="pre">HMMMode.LIKELIHOOD_LOG</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.MEA"><code class="docutils literal notranslate"><span class="pre">HMMMode.MEA</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.POSTERIOR"><code class="docutils literal notranslate"><span class="pre">HMMMode.POSTERIOR</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.hmm.HMMMode.VITERBI"><code class="docutils literal notranslate"><span class="pre">HMMMode.VITERBI</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#configuration">Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.config.ModelConfig"><code class="docutils literal notranslate"><span class="pre">ModelConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.config.ModelConfig.model_config"><code class="docutils literal notranslate"><span class="pre">ModelConfig.model_config</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.config.with_config"><code class="docutils literal notranslate"><span class="pre">with_config()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#emitters">Emitters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.emitter.Emitter"><code class="docutils literal notranslate"><span class="pre">Emitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.Emitter.emission_scores"><code class="docutils literal notranslate"><span class="pre">Emitter.emission_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.Emitter.matrix"><code class="docutils literal notranslate"><span class="pre">Emitter.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.Emitter.sample"><code class="docutils literal notranslate"><span class="pre">Emitter.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.Emitter.state_emissions"><code class="docutils literal notranslate"><span class="pre">Emitter.state_emissions()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.emitter.PaddingEmitter"><code class="docutils literal notranslate"><span class="pre">PaddingEmitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.PaddingEmitter.allow"><code class="docutils literal notranslate"><span class="pre">PaddingEmitter.allow</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.PaddingEmitter.emission_scores"><code class="docutils literal notranslate"><span class="pre">PaddingEmitter.emission_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.emitter.PaddingEmitter.share"><code class="docutils literal notranslate"><span class="pre">PaddingEmitter.share</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#transitioners">Transitioners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.transitioner.TransitionMode"><code class="docutils literal notranslate"><span class="pre">TransitionMode</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.TransitionMode.ALLOWED"><code class="docutils literal notranslate"><span class="pre">TransitionMode.ALLOWED</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.TransitionMode.LOG_SUM_EXP"><code class="docutils literal notranslate"><span class="pre">TransitionMode.LOG_SUM_EXP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.TransitionMode.MAX"><code class="docutils literal notranslate"><span class="pre">TransitionMode.MAX</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.TransitionMode.REVERSE"><code class="docutils literal notranslate"><span class="pre">TransitionMode.REVERSE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.TransitionMode.SUM"><code class="docutils literal notranslate"><span class="pre">TransitionMode.SUM</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.transitioner.Transitioner"><code class="docutils literal notranslate"><span class="pre">Transitioner</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.allow_start"><code class="docutils literal notranslate"><span class="pre">Transitioner.allow_start</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.matrix"><code class="docutils literal notranslate"><span class="pre">Transitioner.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.mode"><code class="docutils literal notranslate"><span class="pre">Transitioner.mode</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.prior_scores"><code class="docutils literal notranslate"><span class="pre">Transitioner.prior_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.prior_start"><code class="docutils literal notranslate"><span class="pre">Transitioner.prior_start</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.sample"><code class="docutils literal notranslate"><span class="pre">Transitioner.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.share_start"><code class="docutils literal notranslate"><span class="pre">Transitioner.share_start</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.start_dist"><code class="docutils literal notranslate"><span class="pre">Transitioner.start_dist()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.transitioner.Transitioner.step"><code class="docutils literal notranslate"><span class="pre">Transitioner.step()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#priors">Priors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.prior.Prior"><code class="docutils literal notranslate"><span class="pre">Prior</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.prior.Prior.prior_scores"><code class="docutils literal notranslate"><span class="pre">Prior.prior_scores()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#generic-base-classes">Generic Base Classes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.generic.Module"><code class="docutils literal notranslate"><span class="pre">Module</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.__call__"><code class="docutils literal notranslate"><span class="pre">Module.__call__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.allow"><code class="docutils literal notranslate"><span class="pre">Module.allow</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.hmm_config"><code class="docutils literal notranslate"><span class="pre">Module.hmm_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.matrix"><code class="docutils literal notranslate"><span class="pre">Module.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.prior"><code class="docutils literal notranslate"><span class="pre">Module.prior</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.prior_scores"><code class="docutils literal notranslate"><span class="pre">Module.prior_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.generic.Module.share"><code class="docutils literal notranslate"><span class="pre">Module.share</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.util.expand_indices"><code class="docutils literal notranslate"><span class="pre">expand_indices()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.util.expand_share"><code class="docutils literal notranslate"><span class="pre">expand_share()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.util.validate_indices"><code class="docutils literal notranslate"><span class="pre">validate_indices()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#tensorflow-backend">TensorFlow Backend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#core-tensorflow-hmm">Core TensorFlow HMM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.hmm.TFHMM"><code class="docutils literal notranslate"><span class="pre">TFHMM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.build"><code class="docutils literal notranslate"><span class="pre">TFHMM.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.call"><code class="docutils literal notranslate"><span class="pre">TFHMM.call()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.emitter"><code class="docutils literal notranslate"><span class="pre">TFHMM.emitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.from_config"><code class="docutils literal notranslate"><span class="pre">TFHMM.from_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.get_config"><code class="docutils literal notranslate"><span class="pre">TFHMM.get_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.joint_log_prob"><code class="docutils literal notranslate"><span class="pre">TFHMM.joint_log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.sample"><code class="docutils literal notranslate"><span class="pre">TFHMM.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.hmm.TFHMM.transitioner"><code class="docutils literal notranslate"><span class="pre">TFHMM.transitioner</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-emitters">TensorFlow Emitters</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.emitter.base.TFEmitter"><code class="docutils literal notranslate"><span class="pre">TFEmitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.base.TFEmitter.call"><code class="docutils literal notranslate"><span class="pre">TFEmitter.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.emitter.base.TFPaddingEmitter"><code class="docutils literal notranslate"><span class="pre">TFPaddingEmitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.base.TFPaddingEmitter.call"><code class="docutils literal notranslate"><span class="pre">TFPaddingEmitter.call()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.base.TFPaddingEmitter.emission_scores"><code class="docutils literal notranslate"><span class="pre">TFPaddingEmitter.emission_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.base.TFPaddingEmitter.matrix"><code class="docutils literal notranslate"><span class="pre">TFPaddingEmitter.matrix()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.build"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.emission_scores"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter.emission_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.initializer"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter.initializer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.matrix"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.sample"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.state_emissions"><code class="docutils literal notranslate"><span class="pre">TFCategoricalEmitter.state_emissions()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.build"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.emission_scores"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.emission_scores()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.from_config"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.from_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.get_config"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.get_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.get_default_initializer"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.get_default_initializer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.init_transform"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.init_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.initializer"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.initializer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.log_prob"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.log_prob()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.matrix"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.matrix_dim"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.matrix_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.mean"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.sample"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.scale"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.scale()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.share"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.share</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.state_emissions"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.state_emissions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.variance"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitter.variance()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitterConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.full_covariance"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitterConfig.full_covariance</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.model_config"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitterConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.temperature"><code class="docutils literal notranslate"><span class="pre">TFMVNormalEmitterConfig.temperature</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-transitioners">TensorFlow Transitioners</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner"><code class="docutils literal notranslate"><span class="pre">TFTransitioner</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.build"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.call"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.call()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.initializer"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.initializer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.initializer_start"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.initializer_start</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.matrix"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.matrix_dim"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.matrix_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.sample"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.start_dist"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.start_dist()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner.step"><code class="docutils literal notranslate"><span class="pre">TFTransitioner.step()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-priors">TensorFlow Priors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.prior.base.TFPrior"><code class="docutils literal notranslate"><span class="pre">TFPrior</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.prior.base.TFPrior.call"><code class="docutils literal notranslate"><span class="pre">TFPrior.call()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.prior.dirichlet.TFDirichletPrior"><code class="docutils literal notranslate"><span class="pre">TFDirichletPrior</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.build"><code class="docutils literal notranslate"><span class="pre">TFDirichletPrior.build()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.initializer"><code class="docutils literal notranslate"><span class="pre">TFDirichletPrior.initializer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.log_dirichlet_pdf"><code class="docutils literal notranslate"><span class="pre">TFDirichletPrior.log_dirichlet_pdf()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.matrix"><code class="docutils literal notranslate"><span class="pre">TFDirichletPrior.matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.prior_scores"><code class="docutils literal notranslate"><span class="pre">TFDirichletPrior.prior_scores()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#algorithms">Algorithms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin"><code class="docutils literal notranslate"><span class="pre">TFForwardBackwardMixin</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.backward_log"><code class="docutils literal notranslate"><span class="pre">TFForwardBackwardMixin.backward_log()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.forward_log"><code class="docutils literal notranslate"><span class="pre">TFForwardBackwardMixin.forward_log()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.forward_scaled"><code class="docutils literal notranslate"><span class="pre">TFForwardBackwardMixin.forward_scaled()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.likelihood_log"><code class="docutils literal notranslate"><span class="pre">TFForwardBackwardMixin.likelihood_log()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.posterior"><code class="docutils literal notranslate"><span class="pre">TFForwardBackwardMixin.posterior()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.viterbi.TFViterbiMixin"><code class="docutils literal notranslate"><span class="pre">TFViterbiMixin</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.viterbi.TFViterbiMixin.maximum_expected_accuracy"><code class="docutils literal notranslate"><span class="pre">TFViterbiMixin.maximum_expected_accuracy()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#hidten.tf.viterbi.TFViterbiMixin.viterbi"><code class="docutils literal notranslate"><span class="pre">TFViterbiMixin.viterbi()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.scan.Scanner"><code class="docutils literal notranslate"><span class="pre">Scanner</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-utilities">TensorFlow Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.ensure_array"><code class="docutils literal notranslate"><span class="pre">ensure_array()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.epsilon"><code class="docutils literal notranslate"><span class="pre">epsilon()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.flat_to_triangular"><code class="docutils literal notranslate"><span class="pre">flat_to_triangular()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.inverse_softplus"><code class="docutils literal notranslate"><span class="pre">inverse_softplus()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.local_to_global_factors"><code class="docutils literal notranslate"><span class="pre">local_to_global_factors()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.log_to_scaled"><code class="docutils literal notranslate"><span class="pre">log_to_scaled()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.log_zero"><code class="docutils literal notranslate"><span class="pre">log_zero()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.logit"><code class="docutils literal notranslate"><span class="pre">logit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.map_diagonal"><code class="docutils literal notranslate"><span class="pre">map_diagonal()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.n_shared_parameters"><code class="docutils literal notranslate"><span class="pre">n_shared_parameters()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.np_dtype"><code class="docutils literal notranslate"><span class="pre">np_dtype()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.safe_div"><code class="docutils literal notranslate"><span class="pre">safe_div()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.safe_log"><code class="docutils literal notranslate"><span class="pre">safe_log()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.scale"><code class="docutils literal notranslate"><span class="pre">scale()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.scaled_to_log"><code class="docutils literal notranslate"><span class="pre">scaled_to_log()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.setup_initializer"><code class="docutils literal notranslate"><span class="pre">setup_initializer()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.shared_tensor"><code class="docutils literal notranslate"><span class="pre">shared_tensor()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.tiny"><code class="docutils literal notranslate"><span class="pre">tiny()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.triangular_to_flat"><code class="docutils literal notranslate"><span class="pre">triangular_to_flat()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#hidten.tf.util.zero_row_softmax"><code class="docutils literal notranslate"><span class="pre">zero_row_softmax()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">HidTen</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">API Reference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/api.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="api-reference">
<h1>API Reference<a class="headerlink" href="#api-reference" title="Link to this heading"></a></h1>
<p>HidTen: A framework for combining hidden Markov models with modern deep learning.</p>
<p>This page provides a complete reference to all public classes, functions, and modules in HidTen.</p>
<section id="core-module">
<h2>Core Module<a class="headerlink" href="#core-module" title="Link to this heading"></a></h2>
<p>The main hidten module exports the primary classes and functions.</p>
</section>
<section id="hmm-classes">
<span id="module-hidten"></span><h2>HMM Classes<a class="headerlink" href="#hmm-classes" title="Link to this heading"></a></h2>
<p>Core HMM implementation with configuration and modes.</p>
<dl class="py class" id="module-hidten.hmm">
<dt class="sig sig-object py" id="hidten.hmm.HMM">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.hmm.</span></span><span class="sig-name descname"><span class="pre">HMM</span></span><a class="headerlink" href="#hidten.hmm.HMM" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T_Tensor</span></code>]</p>
<p>A modular hidden Markov model (HMM).</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMM.add_emitter">
<span class="sig-name descname"><span class="pre">add_emitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emitter</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMM.add_emitter" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>emitter</strong> (<a class="reference internal" href="#hidten.emitter.Emitter" title="hidten.emitter.Emitter"><em>Emitter</em></a><em>[</em><em>T_Tensor</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMM.config">
<span class="sig-name descname"><span class="pre">config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.hmm.HMMConfig" title="hidten.hmm.HMMConfig"><span class="pre">HMMConfig</span></a></em><a class="headerlink" href="#hidten.hmm.HMM.config" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMM.emission_scores">
<span class="sig-name descname"><span class="pre">emission_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMM.emission_scores" title="Link to this definition"></a></dt>
<dd><p>Computes the joint emission scores for all emitters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension. It is
possible to also supply a tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code>,
if all heads should receive the same input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The joint emission scores of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.hmm.HMM.emitter">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">emitter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#hidten.emitter.Emitter" title="hidten.emitter.Emitter"><span class="pre">Emitter</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T_Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hidten.hmm.HMM.emitter" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMM.joint_log_prob">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">joint_log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMM.joint_log_prob" title="Link to this definition"></a></dt>
<dd><p>Computes the joint log-probability of the observations <code class="docutils literal notranslate"><span class="pre">o</span></code>
and the states <code class="docutils literal notranslate"><span class="pre">x</span></code>, i.e. <code class="docutils literal notranslate"><span class="pre">P(o,</span> <span class="pre">x)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
moheadsdels and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>states</strong> (<em>Tensor</em>) – The hidden state indices of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The joint log-probability of the observations and
the states of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMM.prior_scores">
<span class="sig-name descname"><span class="pre">prior_scores</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMM.prior_scores" title="Link to this definition"></a></dt>
<dd><p>Calculates the prior scores for the HMM.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The prior scores of shape <code class="docutils literal notranslate"><span class="pre">(H)</span></code>, where <code class="docutils literal notranslate"><span class="pre">H</span></code> is
the number of heads.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMM.sample">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMM.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a number of tensors from the HMM by repeatedly
sampling states based on possible state transitions and
afterward sampling possbile emissions from these states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> (<em>int</em>) – Number of sequences to sample.</p></li>
<li><p><strong>T</strong> (<em>int</em>) – Number of time steps to sample.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>State tensor of
shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code> and emission tensors (as many as
emitters in the HMM) of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where
<code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states and <code class="docutils literal notranslate"><span class="pre">D</span></code> is the size of
the emission alphabet.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">tuple[tf.Tensor,</span> <span class="pre">tuple[tf.Tensor,</span> <span class="pre">...]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.hmm.HMM.transitioner">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transitioner</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.transitioner.Transitioner" title="hidten.transitioner.Transitioner"><span class="pre">Transitioner</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T_Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hidten.hmm.HMM.transitioner" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMM.use_padding">
<span class="sig-name descname"><span class="pre">use_padding</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMM.use_padding" title="Link to this definition"></a></dt>
<dd><p>Returns true if the HMM support variable length inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="hidten.hmm.HMMConfig">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.hmm.</span></span><span class="sig-name descname"><span class="pre">HMMConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_states</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMMConfig" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.config.ModelConfig" title="hidten.config.ModelConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelConfig</span></code></a></p>
<p>The basic configuration for any HMM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>)</p></li>
<li><p><strong>heads</strong> (<em>int</em>)</p></li>
<li><p><strong>max_states</strong> (<em>int</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMConfig.heads">
<span class="sig-name descname"><span class="pre">heads</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#hidten.hmm.HMMConfig.heads" title="Link to this definition"></a></dt>
<dd><p>Number of heads in the HMM. If not specified, can be inferred by
the length of <code class="docutils literal notranslate"><span class="pre">states</span></code>. Defaults to 1.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMConfig.max_states">
<span class="sig-name descname"><span class="pre">max_states</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#hidten.hmm.HMMConfig.max_states" title="Link to this definition"></a></dt>
<dd><p>Maximal number of states across all HMM heads.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMConfig.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{'frozen':</span> <span class="pre">True}</span></em><a class="headerlink" href="#hidten.hmm.HMMConfig.model_config" title="Link to this definition"></a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMConfig.states">
<span class="sig-name descname"><span class="pre">states</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hidten.hmm.HMMConfig.states" title="Link to this definition"></a></dt>
<dd><p>The number of states in each head of the HMM. Can also be given
as a single integer and is automatically expanded to the given
number of heads.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.hmm.HMMConfig.validate_config">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">validate_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMMConfig.validate_config" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.hmm.</span></span><span class="sig-name descname"><span class="pre">HMMMode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.hmm.HMMMode" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>Collection of modes for an HMM. Changing the mode leads to a
different behaviour when calling an <code class="xref py py-class docutils literal notranslate"><span class="pre">hidten.HMM</span></code> as a
function by <code class="docutils literal notranslate"><span class="pre">__call__</span></code>.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.BACKWARD_LOG">
<span class="sig-name descname"><span class="pre">BACKWARD_LOG</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.BACKWARD_LOG" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of the logarithmic backward variables.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.EMISSION_SCORES">
<span class="sig-name descname"><span class="pre">EMISSION_SCORES</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">7</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.EMISSION_SCORES" title="Link to this definition"></a></dt>
<dd><p>Only outputs the scores of the given emissions without utilizing
any transitions of the model.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.FORWARD_LOG">
<span class="sig-name descname"><span class="pre">FORWARD_LOG</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.FORWARD_LOG" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of the logarithmic forward variables.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.FORWARD_SCALED">
<span class="sig-name descname"><span class="pre">FORWARD_SCALED</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.FORWARD_SCALED" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of the scaled forward variables.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.LIKELIHOOD_LOG">
<span class="sig-name descname"><span class="pre">LIKELIHOOD_LOG</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">3</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.LIKELIHOOD_LOG" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of the log-likelihood.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.MEA">
<span class="sig-name descname"><span class="pre">MEA</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">6</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.MEA" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of MEA state sequences.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.POSTERIOR">
<span class="sig-name descname"><span class="pre">POSTERIOR</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.POSTERIOR" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of posterior state distributions.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.hmm.HMMMode.VITERBI">
<span class="sig-name descname"><span class="pre">VITERBI</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">5</span></em><a class="headerlink" href="#hidten.hmm.HMMMode.VITERBI" title="Link to this definition"></a></dt>
<dd><p>Enables calculation of Viterbi state sequences.</p>
</dd></dl>

</dd></dl>

</section>
<section id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Link to this heading"></a></h2>
<p>Base configuration classes and decorators for model setup.</p>
<dl class="py class" id="module-hidten.config">
<dt class="sig sig-object py" id="hidten.config.ModelConfig">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.config.</span></span><span class="sig-name descname"><span class="pre">ModelConfig</span></span><a class="headerlink" href="#hidten.config.ModelConfig" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseModel</span></code></p>
<p>A base model configuration class that new config classes should
inherit from. A method <code class="docutils literal notranslate"><span class="pre">self.validate_config</span></code> can be defined where
value errors can be thrown or fields can be updated.</p>
<dl class="field-list simple">
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.config.ModelConfig.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#hidten.config.ModelConfig.model_config" title="Link to this definition"></a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.config.with_config">
<span class="sig-prename descclassname"><span class="pre">hidten.config.</span></span><span class="sig-name descname"><span class="pre">with_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.config.with_config" title="Link to this definition"></a></dt>
<dd><p>Decorator for any class that requires a number of simple
configuration attributes. Expects the decorated class to have a
<a class="reference internal" href="#hidten.config.ModelConfig" title="hidten.config.ModelConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelConfig</span></code></a> object of name <code class="docutils literal notranslate"><span class="pre">config</span></code>. Adds methods
<code class="docutils literal notranslate"><span class="pre">from_config</span></code> and <code class="docutils literal notranslate"><span class="pre">get_config</span></code> to the class, as well as an
attribute <code class="docutils literal notranslate"><span class="pre">config_cls</span></code> that is the type of the given config.</p>
<p>Example use case:
<a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
class MyClassConfig(ModelConfig):</p>
<blockquote>
<div><p>n: int
p: float</p>
</div></blockquote>
<p>&#64;with_config(MyClassConfig)
class MyClass:</p>
<blockquote>
<div><dl>
<dt>def __init__(self, <a href="#id5"><span class="problematic" id="id6">**</span></a>kwargs) -&gt; None:</dt><dd><p>self.config = self.config_cls(<a href="#id7"><span class="problematic" id="id8">**</span></a>kwargs)</p>
<p>self.other_init_attr = 62 * self.config.n</p>
</dd>
</dl>
</div></blockquote>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config_class</strong> (<em>type</em>) – Class that inherits from
<a class="reference internal" href="#hidten.config.ModelConfig" title="hidten.config.ModelConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelConfig</span></code></a>.</p></li>
<li><p><strong>overwrite_init</strong> (<em>bool</em><em>, </em><em>optional</em>) – If set to True, overwrites the
<code class="docutils literal notranslate"><span class="pre">__init__</span></code> method of the decorated class to automatically
create the <code class="docutils literal notranslate"><span class="pre">self.config</span></code> attribute. A new method called
<code class="docutils literal notranslate"><span class="pre">self.post_config_init</span></code> can be implemented that is called
at the end of the overwritten <code class="docutils literal notranslate"><span class="pre">__init__</span></code>. Defaults to
manual <code class="docutils literal notranslate"><span class="pre">__init__</span></code> implementation.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Callable</em>[[type[<em>T_Model</em>]], type[<em>T_Model</em>]]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="emitters">
<h2>Emitters<a class="headerlink" href="#emitters" title="Link to this heading"></a></h2>
<p>Emission models that map observations to feature values.</p>
<dl class="py class" id="module-hidten.emitter">
<dt class="sig sig-object py" id="hidten.emitter.Emitter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.emitter.</span></span><span class="sig-name descname"><span class="pre">Emitter</span></span><a class="headerlink" href="#hidten.emitter.Emitter" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.generic.Module" title="hidten.generic.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T_Tensor</span></code>]</p>
<p>The Emitter base class.</p>
<p>An emitter is a module that maps sequences of observations to
feature values. The feature values decribe how likely each
observation is to be emitted by each hidden state.</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.emitter.Emitter.emission_scores">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">emission_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.emitter.Emitter.emission_scores" title="Link to this definition"></a></dt>
<dd><p>Computes how likely each observation is emitted by any
hidden state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em>) – The observation sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code> or <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the
size of the emission alphabet.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden states.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.emitter.Emitter.matrix">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.emitter.Emitter.matrix" title="Link to this definition"></a></dt>
<dd><p>Calculates the emission matrix based on parameters of this
class.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The emission matrix of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">K)</span></code> where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads, <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of
hidden states and <code class="docutils literal notranslate"><span class="pre">K</span></code> is the <code class="docutils literal notranslate"><span class="pre">matrix_dim</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.emitter.Emitter.sample">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.emitter.Emitter.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a possible emission given the current state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>Tensor</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">B</span></code>
is a batch dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads of
the HMM and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Emission tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.emitter.Emitter.state_emissions">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">state_emissions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.emitter.Emitter.state_emissions" title="Link to this definition"></a></dt>
<dd><p>Computes how likely any observation is emitted by the
given hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>states</strong> (<em>Tensor</em>) – The input state sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden
states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The emission distributions of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the size of the
emission alphabet.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="hidten.emitter.PaddingEmitter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.emitter.</span></span><span class="sig-name descname"><span class="pre">PaddingEmitter</span></span><a class="headerlink" href="#hidten.emitter.PaddingEmitter" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.emitter.Emitter" title="hidten.emitter.Emitter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Emitter</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T_Tensor</span></code>]</p>
<p>A specialized emitter to handle padding tracks. Adding this
emitter makes an HMM support variable-length sequences. Accepts
padding as a binary input track where “true” or “1” indicates a
non-padded position that should be used in calculations.</p>
<dl class="py property">
<dt class="sig sig-object py" id="hidten.emitter.PaddingEmitter.allow">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allow</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></em><a class="headerlink" href="#hidten.emitter.PaddingEmitter.allow" title="Link to this definition"></a></dt>
<dd><p>Not supported for PaddingEmitter.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.emitter.PaddingEmitter.emission_scores">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">emission_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.emitter.PaddingEmitter.emission_scores" title="Link to this definition"></a></dt>
<dd><p>Returns emission scores with the following scheme:</p>
<blockquote>
<div><blockquote>
<div><p>input 0 | input 1</p>
</div></blockquote>
<dl class="simple">
<dt>—————————<a href="#id13"><span class="problematic" id="id14">|</span></a>——————–</dt><dd><p>padding emission state  |    1     |    0
all other states        |    0     |    1</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em>) – The observation sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code> or <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the
size of the emission alphabet.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden states including an
internal, appended padding emission state.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.emitter.PaddingEmitter.share">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">share</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hidten.emitter.PaddingEmitter.share" title="Link to this definition"></a></dt>
<dd><p>Not supported for PaddingEmitter.</p>
</dd></dl>

</dd></dl>

</section>
<section id="transitioners">
<h2>Transitioners<a class="headerlink" href="#transitioners" title="Link to this heading"></a></h2>
<p>Transition models that handle state-to-state transitions.</p>
<dl class="py class" id="module-hidten.transitioner">
<dt class="sig sig-object py" id="hidten.transitioner.TransitionMode">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.transitioner.</span></span><span class="sig-name descname"><span class="pre">TransitionMode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.transitioner.TransitionMode" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">IntFlag</span></code></p>
<p>Collection of modes for the transitioner step.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.transitioner.TransitionMode.ALLOWED">
<span class="sig-name descname"><span class="pre">ALLOWED</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">8</span></em><a class="headerlink" href="#hidten.transitioner.TransitionMode.ALLOWED" title="Link to this definition"></a></dt>
<dd><p>Instead of the regular transition matrix, uses a matrix that contains
ones for allowed transitions and zeros otherwise.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.transitioner.TransitionMode.LOG_SUM_EXP">
<span class="sig-name descname"><span class="pre">LOG_SUM_EXP</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">2</span></em><a class="headerlink" href="#hidten.transitioner.TransitionMode.LOG_SUM_EXP" title="Link to this definition"></a></dt>
<dd><p>Calculates the log-sum-exp over the latent states.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.transitioner.TransitionMode.MAX">
<span class="sig-name descname"><span class="pre">MAX</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">4</span></em><a class="headerlink" href="#hidten.transitioner.TransitionMode.MAX" title="Link to this definition"></a></dt>
<dd><p>Computes the maximum over the latent states.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.transitioner.TransitionMode.REVERSE">
<span class="sig-name descname"><span class="pre">REVERSE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">16</span></em><a class="headerlink" href="#hidten.transitioner.TransitionMode.REVERSE" title="Link to this definition"></a></dt>
<dd><p>Computes steps in reverse order.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.transitioner.TransitionMode.SUM">
<span class="sig-name descname"><span class="pre">SUM</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#hidten.transitioner.TransitionMode.SUM" title="Link to this definition"></a></dt>
<dd><p>Sums over the latent states.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.transitioner.</span></span><span class="sig-name descname"><span class="pre">Transitioner</span></span><a class="headerlink" href="#hidten.transitioner.Transitioner" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.generic.Module" title="hidten.generic.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T_Tensor</span></code>]</p>
<p>The Transitioner base class.</p>
<p>A transitioner is a module that implements a discrete time step of a
Markov chain for a given number of heads. The state graph of each
head can be restricted in the number of states and the allowed
transitions between states.</p>
<dl class="py property">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.allow_start">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allow_start</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></em><a class="headerlink" href="#hidten.transitioner.Transitioner.allow_start" title="Link to this definition"></a></dt>
<dd><p>Restrict the starting distribution by only allowing the given
states. If this method is not called before the model is built,
all states are allowed.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Array of pairs <code class="docutils literal notranslate"><span class="pre">(h,</span> <span class="pre">i)</span></code>, where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">i</span></code> is an allowed starting state for head <code class="docutils literal notranslate"><span class="pre">h</span></code>. If
only tuples of one index <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">)</span></code> or integers <code class="docutils literal notranslate"><span class="pre">i</span></code> are
given, they are assumed to be true in each head.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>indices (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.matrix">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.transitioner.Transitioner.matrix" title="Link to this definition"></a></dt>
<dd><p>Computes the state transition matrices for each model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The state transition probabilities of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">Q)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.mode">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">mode</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.transitioner.TransitionMode" title="hidten.transitioner.TransitionMode"><span class="pre">TransitionMode</span></a></em><a class="headerlink" href="#hidten.transitioner.Transitioner.mode" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.prior_scores">
<span class="sig-name descname"><span class="pre">prior_scores</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.transitioner.Transitioner.prior_scores" title="Link to this definition"></a></dt>
<dd><p>Calculates the prior scores for the modules parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The prior scores of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">Q</span></code> is
the number of hidden states in the HMM that uses this module.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.prior_start">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prior_start</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.prior.Prior" title="hidten.prior.Prior"><span class="pre">Prior</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T_Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#hidten.transitioner.Transitioner.prior_start" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.sample">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.transitioner.Transitioner.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a possible next state given the previous.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">B</span></code> is a batch dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of
heads of the HMM and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states. If
no state is supplied, the Transitioner uses the start
distribution with <code class="docutils literal notranslate"><span class="pre">B=1</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Next state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.share_start">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">share_start</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hidten.transitioner.Transitioner.share_start" title="Link to this definition"></a></dt>
<dd><p>Allows to share parameters of the start distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em> of </em><em>ranges</em><em> or </em><em>indices</em>) – A sequence of index
pairs <code class="docutils literal notranslate"><span class="pre">(a,b)</span></code> where <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are indices of the
tuples in <code class="docutils literal notranslate"><span class="pre">Transitioner.allow_start</span></code>. It has to be of
the same length as the initial values given for the
start distribution. Alternatively, it can be a list of
indices of the same length as <code class="docutils literal notranslate"><span class="pre">allow_start</span></code>. These
indices are then used to mark which value in the given
initial values will be used.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.start_dist">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">start_dist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.transitioner.Transitioner.start_dist" title="Link to this definition"></a></dt>
<dd><p>Computes the initial distribution for each model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The start distributions of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.transitioner.Transitioner.step">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.transitioner.Transitioner.step" title="Link to this definition"></a></dt>
<dd><p>Performs a single time step of the Markov chain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – The input tensor of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">Q)</span></code>.
<code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads
and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="priors">
<h2>Priors<a class="headerlink" href="#priors" title="Link to this heading"></a></h2>
<p>Prior distributions for model parameters.</p>
<dl class="py class" id="module-hidten.prior">
<dt class="sig sig-object py" id="hidten.prior.Prior">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.prior.</span></span><span class="sig-name descname"><span class="pre">Prior</span></span><a class="headerlink" href="#hidten.prior.Prior" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.generic.Module" title="hidten.generic.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T_Tensor</span></code>]</p>
<p>The prior base class.</p>
<p>A prior is a module takes as input a tensor of shape <cite>(…, Q, K)</cite>, where
<cite>Q</cite> is the number of hidden states and <cite>K</cite> is a kernel size - representing
the parameters of another module.
The prior rates this parameter set, usually in a probabilistic way, and
returns <cite>prior_scores</cite> that rate how likely the parameters are.</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.prior.Prior.prior_scores">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prior_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.prior.Prior.prior_scores" title="Link to this definition"></a></dt>
<dd><p>Computes prior scores for the input values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>Tensor</em>) – The input values of shape
<code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the prior feature dimension.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The prior scores of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(H)</span></code> with prior scores for each head summed over the
states.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="generic-base-classes">
<h2>Generic Base Classes<a class="headerlink" href="#generic-base-classes" title="Link to this heading"></a></h2>
<p>Abstract base classes for modules and distributions.</p>
<dl class="py class" id="module-hidten.generic">
<dt class="sig sig-object py" id="hidten.generic.Module">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.generic.</span></span><span class="sig-name descname"><span class="pre">Module</span></span><a class="headerlink" href="#hidten.generic.Module" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T_Tensor</span></code>]</p>
<p>Base class for all modules in the HMM framework.</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.generic.Module.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.generic.Module.__call__" title="Link to this definition"></a></dt>
<dd><p>Calls the module with the given observations and returns the
result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Each tensor i should be broadcastable to
the shape <code class="docutils literal notranslate"><span class="pre">(N_1,</span> <span class="pre">..,</span> <span class="pre">N_k,</span> <span class="pre">D_{in}^{(i)})</span></code>, i.e. they
agree on all dimensions except for the last dimension
<code class="docutils literal notranslate"><span class="pre">D_{in}^{(i)}</span></code>, the individual feature dimensions.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output of shape <code class="docutils literal notranslate"><span class="pre">(N_1,</span> <span class="pre">..,</span> <span class="pre">N_k,</span> <span class="pre">D_{out})</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.generic.Module.allow">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">allow</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span></em><a class="headerlink" href="#hidten.generic.Module.allow" title="Link to this definition"></a></dt>
<dd><p>Restrict the matrix of the module by only allowing a subset
of the matrix entries to be modeled. If this method is not
called before the model is built, a dense matrix is modeled
(everything allowed).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>Array of triplets <code class="docutils literal notranslate"><span class="pre">(h,</span> <span class="pre">i,</span> <span class="pre">j)</span></code>,</dt><dd><p>where <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> is an allowed matrix entry of state
<code class="docutils literal notranslate"><span class="pre">i</span></code> to column <code class="docutils literal notranslate"><span class="pre">j</span></code> for some head index <code class="docutils literal notranslate"><span class="pre">h</span></code>. For
emitters, <code class="docutils literal notranslate"><span class="pre">j</span></code> refers to an symbol in the emission
alphabet, for transitioners <code class="docutils literal notranslate"><span class="pre">j</span></code> refers to another
state. If pairs <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> are given, they are assumed
to be the same for all available heads. Therefore, they
are internally expanded to triplets. The order of
indices given remains throughout the Module. If an
initializer is specified, values in this intializer
always correspond to the (possibly automatically)
expanded triplets.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>indices (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.generic.Module.hmm_config">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hmm_config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.hmm.HMMConfig" title="hidten.hmm.HMMConfig"><span class="pre">HMMConfig</span></a></em><a class="headerlink" href="#hidten.generic.Module.hmm_config" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.generic.Module.matrix">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.generic.Module.matrix" title="Link to this definition"></a></dt>
<dd><p>Calculates a matrix based on a parameter kernel for this
module. This could be a transition matrix or a matrix describing
emission distributions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The emission matrix of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">R)</span></code> where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads, <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of
hidden states and <code class="docutils literal notranslate"><span class="pre">R</span></code> is a feature dimension.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.generic.Module.prior">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prior</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.prior.Prior" title="hidten.prior.Prior"><span class="pre">Prior</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T_Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#hidten.generic.Module.prior" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.generic.Module.prior_scores">
<span class="sig-name descname"><span class="pre">prior_scores</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.generic.Module.prior_scores" title="Link to this definition"></a></dt>
<dd><p>Calculates the prior scores for the modules parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The prior scores of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">Q</span></code></dt><dd><p>is the number of hidden states in the HMM that uses this
module.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.generic.Module.share">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">share</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#hidten.generic.Module.share" title="Link to this definition"></a></dt>
<dd><p>Defines if some parameters of the module are shared among
different states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em> of </em><em>ranges</em><em> or </em><em>list</em><em> of </em><em>indices</em><em> or </em><em>array</em><em> of </em><em>indices</em>) – A sequence of index
pairs <code class="docutils literal notranslate"><span class="pre">(a,b)</span></code> where <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are indices of the
tuples in <code class="docutils literal notranslate"><span class="pre">allow</span></code>. It has to be of the same
length as the initial values given for the emission
kernel. Alternatively, it can be a list of indices of
the same length as <code class="docutils literal notranslate"><span class="pre">allow</span></code>. These indices are then
used to mark which value in the given initial values
will be used.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Array of indices of the same length as</dt><dd><p><code class="docutils literal notranslate"><span class="pre">allow</span></code>, where indices in <code class="docutils literal notranslate"><span class="pre">share</span></code> mark which values
in the parameter kernel are shared.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>share (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Link to this heading"></a></h2>
<p>Utility functions and helper classes.</p>
<dl class="py function" id="module-hidten.util">
<dt class="sig sig-object py" id="hidten.util.expand_indices">
<span class="sig-prename descclassname"><span class="pre">hidten.util.</span></span><span class="sig-name descname"><span class="pre">expand_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inner_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_head</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.util.expand_indices" title="Link to this definition"></a></dt>
<dd><p>Expands tuples in a given list to the given <code class="docutils literal notranslate"><span class="pre">inner_length</span></code>. All
tuples should be of <code class="docutils literal notranslate"><span class="pre">inner_length</span></code> or <code class="docutils literal notranslate"><span class="pre">inner_length-1</span></code>. Shorter
tuples <code class="docutils literal notranslate"><span class="pre">(i_1,</span> <span class="pre">...,</span> <span class="pre">i_p)</span></code> are expanded to <code class="docutils literal notranslate"><span class="pre">(j,</span> <span class="pre">i_1,</span> <span class="pre">...,</span> <span class="pre">i_p)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">j=1,</span> <span class="pre">...,</span> <span class="pre">max_head</span></code>. They are expanded in their original
position, shifting later specified tuples by a number of
<code class="docutils literal notranslate"><span class="pre">max_head-1</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>sequence</em><em> of </em><em>sequence</em><em> of </em><em>int</em>) – The sequence of tuples of
integers to expand. The inner sequence can also be an
integer, which is internally replaced by a tuple of length
one.</p></li>
<li><p><strong>inner_length</strong> (<em>int</em>) – Target length of the given tuples.</p></li>
<li><p><strong>max_head</strong> (<em>int</em>) – Maximal first index in the tuples.</p></li>
<li><p><strong>max_index</strong> (<em>list</em><em>[</em><em>int</em><em> | </em><em>list</em><em>[</em><em>int</em><em>]</em><em>]</em><em>, </em><em>optional</em>) – List of maximal
possible indices <code class="docutils literal notranslate"><span class="pre">(i_1,</span> <span class="pre">...,</span> <span class="pre">i_p)</span></code> to use over different
heads <code class="docutils literal notranslate"><span class="pre">j</span></code>. If the maximal indices are lists themselves,
they are understood per-axes. For example,
<code class="docutils literal notranslate"><span class="pre">max_index=[(3,</span> <span class="pre">5),</span> <span class="pre">(2,</span> <span class="pre">3)]</span></code> are maximal indices for two
heads, in which the first head has a tensor of shape
<code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">5)</span></code>. Defaults to no index checking.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[tuple[int, …]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.util.expand_share">
<span class="sig-prename descclassname"><span class="pre">hidten.util.</span></span><span class="sig-name descname"><span class="pre">expand_share</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">share</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.util.expand_share" title="Link to this definition"></a></dt>
<dd><p>Converts a given representation of shared parameters to the
internally used representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>share</strong> (<em>list</em><em> of </em><em>ranges</em><em> or </em><em>indices</em>) – If a list of indices is
given, it is left unchanged. For a given list of ranges
<code class="docutils literal notranslate"><span class="pre">(a,b)</span></code>, the method returns a list of ascending indices of
length <code class="docutils literal notranslate"><span class="pre">N</span></code> where the indices in <code class="docutils literal notranslate"><span class="pre">list[a:b]</span></code> are the
same.</p></li>
<li><p><strong>N</strong> (<em>int</em>) – Size of the resulting list, which is equal to the
number of virtual parameters. With shared parameters, this
is larger than the actual number of parameters.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>list[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.util.validate_indices">
<span class="sig-prename descclassname"><span class="pre">hidten.util.</span></span><span class="sig-name descname"><span class="pre">validate_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.util.validate_indices" title="Link to this definition"></a></dt>
<dd><p>Validates the indices. Valid indices are those such that all
states have at least one outgoing edge in each head and there
are no multi-edges between states of the same head.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em> of </em><em>triplets</em>) – List of triplets <code class="docutils literal notranslate"><span class="pre">(h,</span> <span class="pre">i,</span> <span class="pre">j)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> is an allowed connection between states
<code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">j</span></code> for some head index <code class="docutils literal notranslate"><span class="pre">m</span></code> of the HMM.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="tensorflow-backend">
<h1>TensorFlow Backend<a class="headerlink" href="#tensorflow-backend" title="Link to this heading"></a></h1>
<p>The TensorFlow backend provides concrete implementations optimized for TensorFlow.</p>
<section id="core-tensorflow-hmm">
<h2>Core TensorFlow HMM<a class="headerlink" href="#core-tensorflow-hmm" title="Link to this heading"></a></h2>
<p>Main TensorFlow implementation of HMM.</p>
<dl class="py class" id="module-hidten.tf.hmm">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.hmm.</span></span><span class="sig-name descname"><span class="pre">TFHMM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code>, <a class="reference internal" href="#hidten.hmm.HMM" title="hidten.hmm.HMM"><code class="xref py py-class docutils literal notranslate"><span class="pre">HMM</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <a class="reference internal" href="#hidten.tf.viterbi.TFViterbiMixin" title="hidten.tf.viterbi.TFViterbiMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFViterbiMixin</span></code></a>, <a class="reference internal" href="#hidten.tf.forward_backward.TFForwardBackwardMixin" title="hidten.tf.forward_backward.TFForwardBackwardMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFForwardBackwardMixin</span></code></a></p>
<p>The basic configuration for any HMM.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM.build" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>TensorShape</em><em> | </em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>] </em><em>| </em><em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>]</em><em>, </em><em>...</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">HMMMode.FORWARD_LOG</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM.call" title="Link to this definition"></a></dt>
<dd><p>Calls the layer with an operation defined by its call mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>mode</strong> (<a class="reference internal" href="#hidten.hmm.HMMMode" title="hidten.hmm.HMMMode"><em>HMMMode</em></a>) – The call mode of the HMM. Defaults to
<code class="docutils literal notranslate"><span class="pre">HMMMode.FORWARD_LOG</span></code>.</p></li>
<li><p><strong>parallel</strong> (<em>int</em>) – The parallel factor for the HMM. This is
equal to the number of sequence chunks that are
processed in parallel. Defaults to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tensor which shape depends on the call mode of</dt><dd><p>the HMM (see TFForwardBackwardMixin and TFViterbiMixin).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.emitter">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">emitter</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#hidten.tf.emitter.base.TFEmitter" title="hidten.tf.emitter.base.TFEmitter"><span class="pre">TFEmitter</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#hidten.tf.hmm.TFHMM.emitter" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.from_config">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM.from_config" title="Link to this definition"></a></dt>
<dd><p>Initializes and returns an object of this class with the
given configuration dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>custom_objects</strong> (<em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>T_Model</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM.get_config" title="Link to this definition"></a></dt>
<dd><p>Returns the config used in the class as a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.joint_log_prob">
<span class="sig-name descname"><span class="pre">joint_log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM.joint_log_prob" title="Link to this definition"></a></dt>
<dd><p>Computes the joint log-probability of the observations <code class="docutils literal notranslate"><span class="pre">o</span></code>
and the states <code class="docutils literal notranslate"><span class="pre">x</span></code>, i.e. <code class="docutils literal notranslate"><span class="pre">P(o,</span> <span class="pre">x)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
moheadsdels and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>states</strong> (<em>Tensor</em>) – The hidden state indices of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H)</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The joint log-probability of the observations and
the states of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">T</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.hmm.TFHMM.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a number of tensors from the HMM by repeatedly
sampling states based on possible state transitions and
afterward sampling possbile emissions from these states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>B</strong> (<em>int</em>) – Number of sequences to sample.</p></li>
<li><p><strong>T</strong> (<em>int</em>) – Number of time steps to sample.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>State tensor of
shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code> and emission tensors (as many as
emitters in the HMM) of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where
<code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states and <code class="docutils literal notranslate"><span class="pre">D</span></code> is the size of
the emission alphabet.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">tuple[tf.Tensor,</span> <span class="pre">tuple[tf.Tensor,</span> <span class="pre">...]]</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.hmm.TFHMM.transitioner">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">transitioner</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference internal" href="#hidten.tf.transitioner.TFTransitioner" title="hidten.tf.transitioner.TFTransitioner"><span class="pre">TFTransitioner</span></a></em><a class="headerlink" href="#hidten.tf.hmm.TFHMM.transitioner" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="tensorflow-emitters">
<h2>TensorFlow Emitters<a class="headerlink" href="#tensorflow-emitters" title="Link to this heading"></a></h2>
<p>TensorFlow-specific emission models.</p>
<dl class="py class" id="module-hidten.tf.emitter.base">
<dt class="sig sig-object py" id="hidten.tf.emitter.base.TFEmitter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.emitter.base.</span></span><span class="sig-name descname"><span class="pre">TFEmitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.base.TFEmitter" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TFLayer</span></code>, <a class="reference internal" href="#hidten.emitter.Emitter" title="hidten.emitter.Emitter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Emitter</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
<p>Base class for TF emitters.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.base.TFEmitter.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emissions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.base.TFEmitter.call" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emissions</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>use_padding</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="hidten.tf.emitter.base.TFPaddingEmitter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.emitter.base.</span></span><span class="sig-name descname"><span class="pre">TFPaddingEmitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.base.TFPaddingEmitter" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code>, <a class="reference internal" href="#hidten.emitter.PaddingEmitter" title="hidten.emitter.PaddingEmitter"><code class="xref py py-class docutils literal notranslate"><span class="pre">PaddingEmitter</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
<p>TensorFlow implementation of the PaddingEmitter.</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.base.TFPaddingEmitter.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">emissions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.base.TFPaddingEmitter.call" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>emissions</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>use_padding</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.base.TFPaddingEmitter.emission_scores">
<span class="sig-name descname"><span class="pre">emission_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.base.TFPaddingEmitter.emission_scores" title="Link to this definition"></a></dt>
<dd><p>Returns emission scores with the following scheme:</p>
<blockquote>
<div><blockquote>
<div><p>input 0 | input 1</p>
</div></blockquote>
<dl class="simple">
<dt>—————————<a href="#id15"><span class="problematic" id="id16">|</span></a>——————–</dt><dd><p>padding emission state  |    1     |    0
all other states        |    0     |    1</p>
</dd>
</dl>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em>) – The observation sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code> or <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the
size of the emission alphabet.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden states including an
internal, appended padding emission state.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.base.TFPaddingEmitter.matrix">
<span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.base.TFPaddingEmitter.matrix" title="Link to this definition"></a></dt>
<dd><p>Calculates the emission matrix based on parameters of this
class.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The emission matrix of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">K)</span></code> where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads, <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of
hidden states and <code class="docutils literal notranslate"><span class="pre">K</span></code> is the <code class="docutils literal notranslate"><span class="pre">matrix_dim</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-hidten.tf.emitter.categorical">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.emitter.categorical.</span></span><span class="sig-name descname"><span class="pre">TFCategoricalEmitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.tf.emitter.base.TFEmitter" title="hidten.tf.emitter.base.TFEmitter"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFEmitter</span></code></a></p>
<p>An emitter for categorical observations.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.build" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>TensorShape</em><em> | </em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>] </em><em>| </em><em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>]</em><em>, </em><em>...</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter.emission_scores">
<span class="sig-name descname"><span class="pre">emission_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.emission_scores" title="Link to this definition"></a></dt>
<dd><p>Computes how likely each observation is emitted by any
hidden state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em>) – The observation sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code> or <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the
size of the emission alphabet.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden states.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter.initializer">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initializer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Initializer</span></em><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.initializer" title="Link to this definition"></a></dt>
<dd><p>The initializer of the emission matrix. Defaults to constant
values.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter.matrix">
<span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.matrix" title="Link to this definition"></a></dt>
<dd><p>Calculates the emission matrix based on parameters of this
class.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The emission matrix of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">K)</span></code> where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads, <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of
hidden states and <code class="docutils literal notranslate"><span class="pre">K</span></code> is the <code class="docutils literal notranslate"><span class="pre">matrix_dim</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a possible emission given the current state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>Tensor</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">B</span></code>
is a batch dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads of
the HMM and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Emission tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.categorical.TFCategoricalEmitter.state_emissions">
<span class="sig-name descname"><span class="pre">state_emissions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.categorical.TFCategoricalEmitter.state_emissions" title="Link to this definition"></a></dt>
<dd><p>Computes how likely any observation is emitted by the
given hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>states</strong> (<em>Tensor</em>) – The input state sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden
states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The emission distributions of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the size of the
emission alphabet.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-hidten.tf.emitter.multivariate_normal">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.emitter.multivariate_normal.</span></span><span class="sig-name descname"><span class="pre">TFMVNormalEmitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.tf.emitter.base.TFEmitter" title="hidten.tf.emitter.base.TFEmitter"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFEmitter</span></code></a></p>
<p>An emitter for multivariate normal distributed observations.
The configuration for a multivariate normal emitter.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.build" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>TensorShape</em><em> | </em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>] </em><em>| </em><em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>]</em><em>, </em><em>...</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.emission_scores">
<span class="sig-name descname"><span class="pre">emission_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.emission_scores" title="Link to this definition"></a></dt>
<dd><p>Computes how likely each observation is emitted by any
hidden state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em>) – The observation sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code> or <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the
size of the emission alphabet.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden states.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.from_config">
<em class="property"><span class="k"><span class="pre">classmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.from_config" title="Link to this definition"></a></dt>
<dd><p>Initializes and returns an object of this class with the
given configuration dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>custom_objects</strong> (<em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>T_Model</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.get_config" title="Link to this definition"></a></dt>
<dd><p>Returns the config used in the class as a dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.get_default_initializer">
<span class="sig-name descname"><span class="pre">get_default_initializer</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.get_default_initializer" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Initializer</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.init_transform">
<span class="sig-name descname"><span class="pre">init_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.init_transform" title="Link to this definition"></a></dt>
<dd><p>Transforms means and (co-)variances to kernel values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.initializer">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initializer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Initializer</span></em><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.initializer" title="Link to this definition"></a></dt>
<dd><p>The initializer of the distribution.
The flat initializer must be resizeable to <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">P)</span></code> where
<code class="docutils literal notranslate"><span class="pre">P</span></code> is the number of distribution parameters per head and
state.</p>
<p>Let <code class="docutils literal notranslate"><span class="pre">D</span></code> be the dimensionality of the observations.
If full covariance is used, then the initializer is required to
contain <code class="docutils literal notranslate"><span class="pre">D</span></code> means followed by <code class="docutils literal notranslate"><span class="pre">D</span></code> variances (<code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">=</span> <span class="pre">2D</span></code>) per
head and state. Otherwise, it is required to contain <code class="docutils literal notranslate"><span class="pre">D</span></code> means
followed by the flat covariance matrix (<code class="docutils literal notranslate"><span class="pre">P</span> <span class="pre">=</span> <span class="pre">D</span> <span class="pre">+</span> <span class="pre">D^2</span></code>). The
full, symmetric covariance matrix is expected.</p>
<p>Defaults to means of zeros and variances of ones.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.log_prob" title="Link to this definition"></a></dt>
<dd><p>Computes the log density function of the observations under
the multivariate normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>Tensor</em>) – The observations to compute the log
probability for. The shape should be <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">D)</span></code> or
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The log probability of the observations under the</dt><dd><p>multivariate normal distribution of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.matrix">
<span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.matrix" title="Link to this definition"></a></dt>
<dd><p>Calculates a tensor with the parameters of the multivariate
normal distributions per head and state. The first <code class="docutils literal notranslate"><span class="pre">D</span></code> values
are the means, the rest are the scales, either diagonal or full.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The emission matrix of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">P)</span></code> where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads, <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of
hidden states and <code class="docutils literal notranslate"><span class="pre">P</span></code> is the number of parameters.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.matrix_dim">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">matrix_dim</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.matrix_dim" title="Link to this definition"></a></dt>
<dd><p>Last dimension of the matrix.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.mean">
<span class="sig-name descname"><span class="pre">mean</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.mean" title="Link to this definition"></a></dt>
<dd><p>The mean vector of the multivariate normal distribution with
shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a possible emission given the current state.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>Tensor</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">B</span></code>
is a batch dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads of
the HMM and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Emission tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.scale">
<span class="sig-name descname"><span class="pre">scale</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.scale" title="Link to this definition"></a></dt>
<dd><p>Computes the scale of the multivariate normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>A Matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> such that <code class="docutils literal notranslate"><span class="pre">covariances</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">&#64;</span> <span class="pre">A^T</span></code></dt><dd><p>of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D,</span> <span class="pre">D)</span></code> if full covariance is used, or
<code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D)</span></code> if diagonal covariance is used.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.share">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">share</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.share" title="Link to this definition"></a></dt>
<dd><p>Defines if some parameters of the module are shared among
different states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>list</em><em> of </em><em>ranges</em><em> or </em><em>list</em><em> of </em><em>indices</em><em> or </em><em>array</em><em> of </em><em>indices</em>) – A sequence of index
pairs <code class="docutils literal notranslate"><span class="pre">(a,b)</span></code> where <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are indices of the
tuples in <code class="docutils literal notranslate"><span class="pre">allow</span></code>. It has to be of the same
length as the initial values given for the emission
kernel. Alternatively, it can be a list of indices of
the same length as <code class="docutils literal notranslate"><span class="pre">allow</span></code>. These indices are then
used to mark which value in the given initial values
will be used.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Array of indices of the same length as</dt><dd><p><code class="docutils literal notranslate"><span class="pre">allow</span></code>, where indices in <code class="docutils literal notranslate"><span class="pre">share</span></code> mark which values
in the parameter kernel are shared.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>share (np.ndarray)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.state_emissions">
<span class="sig-name descname"><span class="pre">state_emissions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.state_emissions" title="Link to this definition"></a></dt>
<dd><p>Computes how likely any observation is emitted by the
given hidden states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>states</strong> (<em>Tensor</em>) – The input state sequences of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of hidden
states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The emission distributions of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D)</span></code>, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is the size of the
emission alphabet.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.variance">
<span class="sig-name descname"><span class="pre">variance</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitter.variance" title="Link to this definition"></a></dt>
<dd><p>The covariance matrix of the multivariate normal distribution
with shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D,</span> <span class="pre">D)</span></code> if full covariance is used, or
<code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D)</span></code> if diagonal covariance is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.emitter.multivariate_normal.</span></span><span class="sig-name descname"><span class="pre">TFMVNormalEmitterConfig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_covariance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.config.ModelConfig" title="hidten.config.ModelConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelConfig</span></code></a></p>
<p>The configuration for a multivariate normal emitter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>full_covariance</strong> (<em>bool</em>)</p></li>
<li><p><strong>temperature</strong> (<em>float</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.full_covariance">
<span class="sig-name descname"><span class="pre">full_covariance</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.full_covariance" title="Link to this definition"></a></dt>
<dd><p>Whether to use a full covariance matrix or a diagonal one.
Defaults to False.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.model_config">
<span class="sig-name descname"><span class="pre">model_config</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">ClassVar</span><span class="p"><span class="pre">[</span></span><span class="pre">ConfigDict</span><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{}</span></em><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.model_config" title="Link to this definition"></a></dt>
<dd><p>Configuration for the model, should be a dictionary conforming to [<cite>ConfigDict</cite>][pydantic.config.ConfigDict].</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.temperature">
<span class="sig-name descname"><span class="pre">temperature</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#hidten.tf.emitter.multivariate_normal.TFMVNormalEmitterConfig.temperature" title="Link to this definition"></a></dt>
<dd><p>Temperature for the multivariate normal distribution.</p>
</dd></dl>

</dd></dl>

</section>
<section id="tensorflow-transitioners">
<h2>TensorFlow Transitioners<a class="headerlink" href="#tensorflow-transitioners" title="Link to this heading"></a></h2>
<p>TensorFlow-specific transition models.</p>
<dl class="py class" id="module-hidten.tf.transitioner">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.transitioner.</span></span><span class="sig-name descname"><span class="pre">TFTransitioner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TFLayer</span></code>, <a class="reference internal" href="#hidten.transitioner.Transitioner" title="hidten.transitioner.Transitioner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transitioner</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.build" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>TensorShape</em><em> | </em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>] </em><em>| </em><em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>]</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.call" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>batch_first</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.initializer">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initializer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Initializer</span></em><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.initializer" title="Link to this definition"></a></dt>
<dd><p>The initializer of the transition values that are allowed in
the Transitioner. Defaults to constant values.</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.initializer_start">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initializer_start</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Initializer</span></em><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.initializer_start" title="Link to this definition"></a></dt>
<dd><p>The initializer of the start distribution of allowed states
in the Transitioner. Defaults to constant values.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.matrix">
<span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.matrix" title="Link to this definition"></a></dt>
<dd><p>Computes the state transition matrices for each model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The state transition probabilities of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">Q)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.matrix_dim">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">matrix_dim</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.matrix_dim" title="Link to this definition"></a></dt>
<dd><p>Last dimension of the matrix.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.sample" title="Link to this definition"></a></dt>
<dd><p>Samples a possible next state given the previous.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>,
where <code class="docutils literal notranslate"><span class="pre">B</span></code> is a batch dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of
heads of the HMM and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states. If
no state is supplied, the Transitioner uses the start
distribution with <code class="docutils literal notranslate"><span class="pre">B=1</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Next state tensor of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.start_dist">
<span class="sig-name descname"><span class="pre">start_dist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.start_dist" title="Link to this definition"></a></dt>
<dd><p>Computes the initial distribution for each model.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The start distributions of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.transitioner.TFTransitioner.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.transitioner.TFTransitioner.step" title="Link to this definition"></a></dt>
<dd><p>Performs a single time step of the Markov chain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – The input tensor of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">Q)</span></code>.
<code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads
and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of states.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="tensorflow-priors">
<h2>TensorFlow Priors<a class="headerlink" href="#tensorflow-priors" title="Link to this heading"></a></h2>
<p>TensorFlow-specific prior models.</p>
<dl class="py class" id="module-hidten.tf.prior.base">
<dt class="sig sig-object py" id="hidten.tf.prior.base.TFPrior">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.prior.base.</span></span><span class="sig-name descname"><span class="pre">TFPrior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.base.TFPrior" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TFLayer</span></code>, <a class="reference internal" href="#hidten.prior.Prior" title="hidten.prior.Prior"><code class="xref py py-class docutils literal notranslate"><span class="pre">Prior</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
<p>Base class for TF priors.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.prior.base.TFPrior.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.base.TFPrior.call" title="Link to this definition"></a></dt>
<dd><p>Calls the prior with the given inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>Tensor</em>) – The input tensor of shape (H, Q, D).</p></li>
<li><p><strong>values</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of shape (H,).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-hidten.tf.prior.dirichlet">
<dt class="sig sig-object py" id="hidten.tf.prior.dirichlet.TFDirichletPrior">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.prior.dirichlet.</span></span><span class="sig-name descname"><span class="pre">TFDirichletPrior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.dirichlet.TFDirichletPrior" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.tf.prior.base.TFPrior" title="hidten.tf.prior.base.TFPrior"><code class="xref py py-class docutils literal notranslate"><span class="pre">TFPrior</span></code></a></p>
<p>A Dirichlet prior for categorical observations. Can be added to a
<code class="xref py py-class docutils literal notranslate"><span class="pre">hidten.tf.categorical.TFCategoricalEmitter</span></code>.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.prior.dirichlet.TFDirichletPrior.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.build" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> (<em>TensorShape</em><em> | </em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>] </em><em>| </em><em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>int</em><em> | </em><em>None</em><em>, </em><em>...</em><em>]</em><em>, </em><em>...</em><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="hidten.tf.prior.dirichlet.TFDirichletPrior.initializer">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">initializer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Initializer</span></em><a class="headerlink" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.initializer" title="Link to this definition"></a></dt>
<dd><p>The initializer of the emission matrix. Defaults to constant
values.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.prior.dirichlet.TFDirichletPrior.log_dirichlet_pdf">
<span class="sig-name descname"><span class="pre">log_dirichlet_pdf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.log_dirichlet_pdf" title="Link to this definition"></a></dt>
<dd><p>Compute the log pdf of a Dirichlet distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – The input values of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D)</span></code>, where the values
must sum to 1 along the last dimension.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The log pdf with shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q)</span></code> matching the batch dimensions</dt><dd><p>of <cite>x</cite>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.prior.dirichlet.TFDirichletPrior.matrix">
<span class="sig-name descname"><span class="pre">matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.matrix" title="Link to this definition"></a></dt>
<dd><p>Calculates a matrix based on a parameter kernel for this
module. This could be a transition matrix or a matrix describing
emission distributions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The emission matrix of shape <code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">R)</span></code> where</dt><dd><p><code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of heads, <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the number of
hidden states and <code class="docutils literal notranslate"><span class="pre">R</span></code> is a feature dimension.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.prior.dirichlet.TFDirichletPrior.prior_scores">
<span class="sig-name descname"><span class="pre">prior_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.prior.dirichlet.TFDirichletPrior.prior_scores" title="Link to this definition"></a></dt>
<dd><p>Computes log-Dirichlet densities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>Tensor</em>) – The input values of shape
<code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">Q,</span> <span class="pre">D)</span></code>, where the values must sum to 1 along
the last dimension.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The prior scores with shape <code class="docutils literal notranslate"><span class="pre">(H)</span></code> with dirichlet log</dt><dd><p>densities for each head summed over the states.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="algorithms">
<h2>Algorithms<a class="headerlink" href="#algorithms" title="Link to this heading"></a></h2>
<p>Core algorithms for inference and learning.</p>
<dl class="py class" id="module-hidten.tf.forward_backward">
<dt class="sig sig-object py" id="hidten.tf.forward_backward.TFForwardBackwardMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.forward_backward.</span></span><span class="sig-name descname"><span class="pre">TFForwardBackwardMixin</span></span><a class="headerlink" href="#hidten.tf.forward_backward.TFForwardBackwardMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.tf.scan.Scanner" title="hidten.tf.scan.Scanner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scanner</span></code></a></p>
<p>Mixin class for the forward-backward algorithm in TensorFlow.
Must not be used otherwise than as a mixin in the TFHMM class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.forward_backward.TFForwardBackwardMixin.backward_log">
<span class="sig-name descname"><span class="pre">backward_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.backward_log" title="Link to this definition"></a></dt>
<dd><p>Runs the vectorized and differentiable backward algorithm and
returns backward log-probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>parallel</strong> (<em>int</em><em>, </em><em>optional</em>) – The parallel factor for the HMM.
Defaults to no parallelization.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The backward log-probabilities for the input</dt><dd><p>sequence of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.forward_backward.TFForwardBackwardMixin.forward_log">
<span class="sig-name descname"><span class="pre">forward_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.forward_log" title="Link to this definition"></a></dt>
<dd><p>Runs the vectorized and differentiable forward algorithm that
calculates logarithmic forward probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>parallel</strong> (<em>int</em><em>, </em><em>optional</em>) – The parallel factor for the HMM.
Defaults to no parallelization.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The forward log-probabilities of</dt><dd><p>the input sequence of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.forward_backward.TFForwardBackwardMixin.forward_scaled">
<span class="sig-name descname"><span class="pre">forward_scaled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.forward_scaled" title="Link to this definition"></a></dt>
<dd><p>Runs the scaled variant of the forward algorithm in
vectorized and differentiable manner.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM heads
and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>parallel</strong> (<em>int</em><em>, </em><em>optional</em>) – The parallel factor for the HMM.
Defaults to no parallelization.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The scaled forward probabilities (not</dt><dd><p>logarithmic, but summing to one over the last dimension)
for the input sequence of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code> and the
scaling factors of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">1)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.forward_backward.TFForwardBackwardMixin.likelihood_log">
<span class="sig-name descname"><span class="pre">likelihood_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.likelihood_log" title="Link to this definition"></a></dt>
<dd><p>Computes the log-likelihood of the observations using the
forward algorithm.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>parallel</strong> (<em>int</em><em>, </em><em>optional</em>) – The parallel factor for the HMM.
Defaults to no parallelization.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The log-likelihood of each observation and head of</dt><dd><p>shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">1)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.forward_backward.TFForwardBackwardMixin.posterior">
<span class="sig-name descname"><span class="pre">posterior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_emission_scores</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.forward_backward.TFForwardBackwardMixin.posterior" title="Link to this definition"></a></dt>
<dd><p>Runs the vectorized and differentiable forward-backward
algorithm and returns the posterior state probabilities.
The result is not logarithmic!</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em>) – Whether to normalize the posterior. If
false, the output will be the naked product of scaled
forward and backward probabilities. This can result in
posterior values &gt; 1 due to numerical errors.</p></li>
<li><p><strong>parallel</strong> (<em>int</em><em>, </em><em>optional</em>) – The parallel factor for the HMM.
Defaults to no parallelization.</p></li>
<li><p><strong>return_emission_scores</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to return the
emission scores.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The posterior state log-probabilities for the input</dt><dd><p>sequence of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>, where <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the
maximum number of states in all HMMs.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-hidten.tf.viterbi">
<dt class="sig sig-object py" id="hidten.tf.viterbi.TFViterbiMixin">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.viterbi.</span></span><span class="sig-name descname"><span class="pre">TFViterbiMixin</span></span><a class="headerlink" href="#hidten.tf.viterbi.TFViterbiMixin" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#hidten.tf.scan.Scanner" title="hidten.tf.scan.Scanner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Scanner</span></code></a></p>
<p>Mixin class for the Viterbi algorithm in TensorFlow.
Must not be used otherwise than as a mixin in the TFHMM class.</p>
<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.viterbi.TFViterbiMixin.maximum_expected_accuracy">
<span class="sig-name descname"><span class="pre">maximum_expected_accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tf.int32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">invalid_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_state_seqs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.viterbi.TFViterbiMixin.maximum_expected_accuracy" title="Link to this definition"></a></dt>
<dd><p>For each batch sequence and each head, computes the state sequence
X with maximum sum of the posterior probabilities and <cite>P(X) &gt; 0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>parallel</strong> (<em>int</em>) – The parallel factor for the HMM.</p></li>
<li><p><strong>output_type</strong> (<em>tf.dtypes.DType</em>) – The type of the output
tensor.</p></li>
<li><p><strong>invalid_state</strong> (<em>int</em>) – Indiates padding and invalid states
(e.g., when no possible state sequence exists.)</p></li>
<li><p><strong>validate_state_seqs</strong> (<em>bool</em>) – If True, the function checks for
the edge case when there is no state sequence with
non-zero probability.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The maximum expected accuracy state sequence</dt><dd><p>for the input sequence of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor (int)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="hidten.tf.viterbi.TFViterbiMixin.viterbi">
<span class="sig-name descname"><span class="pre">viterbi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parallel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tf.int32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_variables</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">invalid_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_state_seqs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaled</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.viterbi.TFViterbiMixin.viterbi" title="Link to this definition"></a></dt>
<dd><p>Computes the most likely state sequences for the given
observations with the Viterbi algorithm.</p>
<p>The implementation is logarithmic (underflow-safe) and capable
of decoding many sequences in parallel on the GPU. Optionally
the function can also parallelize over the sequence length at
the cost of memory usage (recommended for long sequences and
HMMs with few states).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>Tensor</em><em> or </em><em>tuple</em><em> of </em><em>Tensors</em>) – The input
sequence(s). Tensor i should be broadcastable to shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">D_i)</span></code> where <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, <code class="docutils literal notranslate"><span class="pre">T</span></code>
is the time dimension, <code class="docutils literal notranslate"><span class="pre">H</span></code> is the number of HMM
heads and <code class="docutils literal notranslate"><span class="pre">D_i</span></code> is the feature dimension.</p></li>
<li><p><strong>parallel</strong> (<em>int</em>) – The parallel factor for the HMM.</p></li>
<li><p><strong>output_type</strong> (<em>tf.dtypes.DType</em>) – The type of the output
tensor.</p></li>
<li><p><strong>return_variables</strong> (<em>bool</em>) – If True, the function returns
additional variables.</p></li>
<li><p><strong>invalid_state</strong> (<em>int</em>) – Indiates padding and invalid states
(e.g., when no possible state sequence exists.)</p></li>
<li><p><strong>validate_state_seqs</strong> (<em>bool</em>) – If True, the function checks for
the edge case when there is no state sequence with
non-zero probability.</p></li>
<li><p><strong>scaled</strong> (<em>bool</em>) – If True, the Viterbi log-probs are scaled by
the maximum log-prob at each time step to improve
numerical stability. Only affects parallel.</p></li>
<li><p><strong>self</strong> (<a class="reference internal" href="#hidten.tf.hmm.TFHMM" title="hidten.tf.hmm.TFHMM"><em>TFHMM</em></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The most likely state sequence for the input</dt><dd><p>sequence of shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H)</span></code>. If return_variables is
True, the function also returns the Viterbi values of
shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor (int)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-hidten.tf.scan">
<dt class="sig sig-object py" id="hidten.tf.scan.Scanner">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">hidten.tf.scan.</span></span><span class="sig-name descname"><span class="pre">Scanner</span></span><a class="headerlink" href="#hidten.tf.scan.Scanner" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

</section>
<section id="tensorflow-utilities">
<h2>TensorFlow Utilities<a class="headerlink" href="#tensorflow-utilities" title="Link to this heading"></a></h2>
<p>TensorFlow-specific utility functions.</p>
<dl class="py function" id="module-hidten.tf.util">
<dt class="sig sig-object py" id="hidten.tf.util.ensure_array">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">ensure_array</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.ensure_array" title="Link to this definition"></a></dt>
<dd><p>Ensures that the input is a numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>ndarray</em><em> | </em><em>list</em><em> | </em><em>float</em><em> | </em><em>int</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.epsilon">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">epsilon</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.epsilon" title="Link to this definition"></a></dt>
<dd><p>Returns a small value to avoid numerical issues depending on the
dtype of <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>list</em><em> | </em><em>tuple</em><em> | </em><em>float</em><em> | </em><em>int</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.flat_to_triangular">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">flat_to_triangular</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">flat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.flat_to_triangular" title="Link to this definition"></a></dt>
<dd><p>Creates triangular matrices from flat vectors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>flat</strong> (<em>Tensor</em>) – A tensor representing lower (or upper) triangular
elements of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">M)</span></code>.</p></li>
<li><p><strong>upper</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the output matrix should be
upper or lower triangular. Defaults to lower.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Tensor with lower (or upper) triangular elements filled</dt><dd><p>from <code class="docutils literal notranslate"><span class="pre">flat</span></code>, with shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">N,</span> <span class="pre">N)</span></code> where
<code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">(-1</span> <span class="pre">+</span> <span class="pre">sqrt(1</span> <span class="pre">+</span> <span class="pre">8</span> <span class="pre">*</span> <span class="pre">M))</span> <span class="pre">/</span> <span class="pre">2</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – if <code class="docutils literal notranslate"><span class="pre">x</span></code> cannot be mapped to a triangular matrix.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.inverse_softplus">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">inverse_softplus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.inverse_softplus" title="Link to this definition"></a></dt>
<dd><p>Compute the element-wise inverse softplus of the input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>tf.Tensor</em>) – Input tensor containing the values to
apply the inverse softplus function.</p></li>
<li><p><strong>x</strong> (<em>Tensor</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor with the same shape as <cite>features</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.local_to_global_factors">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">local_to_global_factors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_sf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">global_almost_scaled</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.local_to_global_factors" title="Link to this definition"></a></dt>
<dd><p>Computes the global scaling factors from the local scaling
factors. Also computes correction factors that convert a locally
scaled tensor to a globally scaled tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_sf</strong> (<em>Tensor</em>) – The local scaling factors of shape
<code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">Z,</span> <span class="pre">1)</span></code>.</p></li>
<li><p><strong>global_almost_scaled</strong> (<em>Tensor</em>) – The global variables scaled up to
the previous step but unscaled for the current step of shape
<code class="docutils literal notranslate"><span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">Z)</span></code>.</p></li>
<li><p><strong>batch_first</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, (only) <code class="docutils literal notranslate"><span class="pre">local_sf</span></code> is
assumed to have shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">Z,</span> <span class="pre">1)</span></code> instead.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">(global_scaled,</span> <span class="pre">global_sf,</span> <span class="pre">correction)</span></code></dt><dd><p>of shapes <code class="docutils literal notranslate"><span class="pre">((H,</span> <span class="pre">B,</span> <span class="pre">Q),</span> <span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">1),</span> <span class="pre">(H,</span> <span class="pre">B,</span> <span class="pre">C,</span> <span class="pre">Z))</span></code>
(independent of the <code class="docutils literal notranslate"><span class="pre">batch_first</span></code> argument).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(Tuple of tensors)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.log_to_scaled">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">log_to_scaled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_probs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.log_to_scaled" title="Link to this definition"></a></dt>
<dd><p>Utility function that converts log probabilities to scaled
probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>log_probs</strong> (<em>Tensor</em>) – The log probabilities of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The scaled probabilities of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">Q)</span></code> and the scaling factors of shape
<code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">T,</span> <span class="pre">H,</span> <span class="pre">1)</span></code> that were used for scaling.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple of Tensors</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.log_zero">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">log_zero</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.log_zero" title="Link to this definition"></a></dt>
<dd><p>Returns the maximum value to avoid numerical issues depending on the
dtype of <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>list</em><em> | </em><em>tuple</em><em> | </em><em>float</em><em> | </em><em>int</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.logit">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">logit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.logit" title="Link to this definition"></a></dt>
<dd><p>Computes the element-wise logit function, which is the inverse to
the sigmoid function: <code class="docutils literal notranslate"><span class="pre">ln(x</span> <span class="pre">/</span> <span class="pre">(1-x))</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>list</em><em> | </em><em>tuple</em><em> | </em><em>float</em><em> | </em><em>int</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.map_diagonal">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">map_diagonal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.map_diagonal" title="Link to this definition"></a></dt>
<dd><p>Applies a function to the batched diagonals of batched matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>fn</strong> (<em>Callable</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.n_shared_parameters">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">n_shared_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.n_shared_parameters" title="Link to this definition"></a></dt>
<dd><p>Calculates the number of shared parameters by a given number of
indices and shared ranges of those indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>ndarray</em>)</p></li>
<li><p><strong>share</strong> (<em>list</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.np_dtype">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">np_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.np_dtype" title="Link to this definition"></a></dt>
<dd><p>Returns the numpy dtype of the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>list</em><em> | </em><em>tuple</em><em> | </em><em>float</em><em> | </em><em>int</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>dtype</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.safe_div">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">safe_div</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_tiny</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.safe_div" title="Link to this definition"></a></dt>
<dd><p>Safely divides the first tensor by the second.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>)</p></li>
<li><p><strong>use_tiny</strong> (<em>bool</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.safe_log">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">safe_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.safe_log" title="Link to this definition"></a></dt>
<dd><p>Computes element-wise logarithm with <cite>output_i=log_zero_val</cite>
where <cite>x_i=0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>TFTensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Element-wise logarithm of x, with log_zero_val where x</dt><dd><p>is 0. Same dtype and shape as x.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>TFTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.scale">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">scale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.scale" title="Link to this definition"></a></dt>
<dd><p>Scales the values by their sum over the last dimension and
returns the scaled values and the scaling factors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>values</strong> (<em>Tensor</em>) – The values to scale, shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">Q)</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The scaled values of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">Q)</span></code>,</dt><dd><p>where the last dimension sums to one, and the scaling
factors of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">1)</span></code> that were used for scaling.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(tuple of Tensors)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.scaled_to_log">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">scaled_to_log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scaled_probs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling_factors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">time_axis</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_cumsum</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.scaled_to_log" title="Link to this definition"></a></dt>
<dd><p>Utility function that converts scaled probabilities to
log-probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scaled_probs</strong> (<em>Tensor</em>) – The scaled probabilities of shape
<code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">T,</span> <span class="pre">...,</span> <span class="pre">Q)</span></code>.</p></li>
<li><p><strong>scaling_factors</strong> (<em>Tensor</em>) – The scaling factors of shape
<code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">T,</span> <span class="pre">...,</span> <span class="pre">1)</span></code> that were used for scaling.</p></li>
<li><p><strong>time_axis</strong> (<em>int</em><em>, </em><em>optional</em>) – The axis along which the time
dimension is located. Defaults to 1.</p></li>
<li><p><strong>return_cumsum</strong> (<em>bool</em><em>, </em><em>optional</em>) – If True, the cumulative sum of
the scaling factors is returned as well. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The log-probabilities of shape</dt><dd><p><code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">T,</span> <span class="pre">...,</span> <span class="pre">Q)</span></code>. If <cite>return_cumsum</cite> is True, a tuple of
tensors is returned, where the first tensor is the
log-probabilities and the second tensor is the cumulative
sum of the scaling factors of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">T,</span> <span class="pre">...,</span> <span class="pre">1)</span></code>.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(Tensor or tuple of Tensors)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.setup_initializer">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">setup_initializer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initializer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate_msg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.setup_initializer" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>initializer</strong> (<em>Initializer</em><em> | </em><em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>list</em><em> | </em><em>float</em>)</p></li>
<li><p><strong>transform</strong> (<em>Callable</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>validate_condition</strong> (<em>Callable</em><em> | </em><em>None</em>)</p></li>
<li><p><strong>validate_msg</strong> (<em>str</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Initializer</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.shared_tensor">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">shared_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.shared_tensor" title="Link to this definition"></a></dt>
<dd><p>Creates a dense tensor with optional parameter sharing using
scatter operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>indices</strong> (<em>T_TFTensor</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">2)</span></code>, dtype int64.</p></li>
<li><p><strong>values</strong> (<em>T_TFTensor</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(K,</span> <span class="pre">)</span></code>, dtype float32.</p></li>
<li><p><strong>shape</strong> (<em>T_TFTensor</em>) – Shape of the resulting tensor.</p></li>
<li><p><strong>share</strong> (<em>T_TFTensor</em><em>, </em><em>optional</em>) – Tensor of shape <code class="docutils literal notranslate"><span class="pre">(K,</span> <span class="pre">)</span></code>, dtype
int32 or int64. Defaults to no parameter sharing.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A dense tensor with shared parameters placed at</dt><dd><p>given indices.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T_TFTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.tiny">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">tiny</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.tiny" title="Link to this definition"></a></dt>
<dd><p>Returns a tiny value to avoid numerical issues depending on the
dtype of <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>list</em><em> | </em><em>tuple</em><em> | </em><em>float</em><em> | </em><em>int</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.triangular_to_flat">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">triangular_to_flat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">triag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.triangular_to_flat" title="Link to this definition"></a></dt>
<dd><p>Creates flat vectors from triangular matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>triag</strong> (<em>tensor</em>) – A tensor representing lower (or upper)
triangular elements of shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">N,</span> <span class="pre">N)</span></code>.</p></li>
<li><p><strong>upper</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the input matrix should be
intepreted as upper or lower triangular. Defaults to lower.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A batch of vector-shaped tensors representing vectorized</dt><dd><p>lower (or upper) triangular elements of <code class="docutils literal notranslate"><span class="pre">triag</span></code>, with
shape <code class="docutils literal notranslate"><span class="pre">(...,</span> <span class="pre">M)</span></code> where <a href="#id17"><span class="problematic" id="id18">``</span></a>M = N * (N + 1).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="hidten.tf.util.zero_row_softmax">
<span class="sig-prename descclassname"><span class="pre">hidten.tf.util.</span></span><span class="sig-name descname"><span class="pre">zero_row_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#hidten.tf.util.zero_row_softmax" title="Link to this definition"></a></dt>
<dd><p>Computes a softmax over the rightmost axis but returns a row of zeros
when the input row contains only log_zero values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="advanced.html" class="btn btn-neutral float-left" title="Advanced" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Felix Becker, Richard Krieg.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>